{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3689ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53457062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(X_train_data, Y_train_data), (X_test_data, Y_test_data) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "938bed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "N = X_train_data.shape  # 60 000 données\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea79ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train_data, (N,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "38e023ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "160ff965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([\n",
    "                [[1,1,1,1], [1,1,1,1],\n",
    "                 [1,1,1,1], [1,1,1,1]],\n",
    "                [[1,1,1,1], [1,1,1,1],\n",
    "                 [1,1,1,1], [1,1,1,1]],\n",
    "                [[1,1,1,1], [1,1,1,1],\n",
    "                 [1,1,1,1], [1,1,1,1]]\n",
    "               ])\n",
    "\n",
    "M = arr.shape\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f18aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_t = np.reshape(arr, (arr.shape[0],4,4,1))\n",
    "#print(arr_t.shape)\n",
    "#print(arr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7250d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9c87559",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test_data, (X_test_data.shape[0],28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b5d06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f926668d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38791e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train_data, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25b2fcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f4681b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== Couche numéro 0 =====\n",
      "Nombre de neurones : 2\n",
      "Nombre d'entrées par neurones : 2\n",
      "Nombre de poids par neurones : 3 \n",
      "\n",
      "    --- Neurone numéro 0 ---\n",
      "    Coefficients [1. 2.]\n",
      "    Biais -3.0\n",
      "    --- Neurone numéro 1 ---\n",
      "    Coefficients [-3. -2.]\n",
      "    Biais 1.0\n",
      "\n",
      "\n",
      "===== Couche numéro 1 =====\n",
      "Nombre de neurones : 1\n",
      "Nombre d'entrées par neurones : 2\n",
      "Nombre de poids par neurones : 3 \n",
      "\n",
      "    --- Neurone numéro 0 ---\n",
      "    Coefficients [1. 1.]\n",
      "    Biais -1.0\n",
      "X_train : [[0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]]\n",
      "Y_train : [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "(4, 2)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from descente import *\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras_facile import *\n",
    "\n",
    "\n",
    "modele = Sequential()\n",
    "\n",
    "# Réseau : \n",
    "# 2 entrées (x,y), \n",
    "# première couche : 2 neurones\n",
    "# seconde couche : 1 neurone\n",
    "# activation = tangente hyperbolique\n",
    "\n",
    "# Première couche : 2 neurones (entrée de dimension 2)\n",
    "modele.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "\n",
    "# Seconde et dernière couche : 1 neurone\n",
    "modele.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "mysgd = optimizers.SGD(learning_rate=1)\n",
    "modele.compile(loss='mean_squared_error', optimizer=mysgd)\n",
    "\n",
    "# poids_a_zeros(modele,0)  # couche 0, tous les poids à zéros\n",
    "# poids_a_zeros(modele,1)  # couche 0, tous les poids à zéros\n",
    "definir_poids(modele,0,0,[1,2],-3)  # couche, rang, [coeffs], biais\n",
    "definir_poids(modele,0,1,[-3,-2],1)  # couche, rang, [coeffs], biais\n",
    "definir_poids(modele,1,0,[1,1],-1)  # couche, rang, [coeffs], biais\n",
    "\n",
    "# definir_poids(modele,0,0,[1,-1],1)  # couche, rang, [coeffs], biais\n",
    "# definir_poids(modele,0,1,[2,-1],-2)  # couche, rang, [coeffs], biais\n",
    "# definir_poids(modele,1,0,[2,-3],-1)  # couche, rang, [coeffs], biais\n",
    "\n",
    "affiche_poids(modele,0)\n",
    "affiche_poids(modele,1)\n",
    "\n",
    "# carré rouge +1\n",
    "# rond bleus 0\n",
    "carres_rouges = [(0,1), (1,0)]\n",
    "ronds_bleus   = [(0,0), (1,1)] \n",
    "\n",
    "X_train = np.array(carres_rouges+ronds_bleus)\n",
    "# rouge = 1, bleu = 0\n",
    "print(f'X_train : {X_train}')\n",
    "Y_train = np.array( [[1]]*len(carres_rouges) + [[0]]*len(ronds_bleus) )\n",
    "\n",
    "print(f'Y_train : {Y_train}')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f67aca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 154s 1us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 16:06:07.966866: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 62s 68ms/step - loss: 4.7210 - accuracy: 0.0755\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 52s 66ms/step - loss: 4.6801 - accuracy: 0.0618\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 53s 68ms/step - loss: 4.1745 - accuracy: 0.0943\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 52s 67ms/step - loss: 3.7867 - accuracy: 0.1445\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 53s 68ms/step - loss: 3.5458 - accuracy: 0.1786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fbe7d060>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5513da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# From mpariente https://stackoverflow.com/questions/51140950/\n",
    "def get_weight_grad(model, inputs, outputs):\n",
    "### Gets gradient of model for given inputs and outputs for all weights\n",
    "    grads = model.optimizer.get_gradients(model.total_loss, model.trainable_weights)\n",
    "    symb_inputs = (model._feed_inputs + model._feed_targets + model._feed_sample_weights)\n",
    "    f = K.function(symb_inputs, grads)\n",
    "    x, y, sample_weight = model._standardize_user_data(inputs, outputs)\n",
    "    output_grad = f(x + y + sample_weight)\n",
    "    return output_grad\n",
    "\n",
    "\n",
    "\n",
    "print('====================')\n",
    "\n",
    "# modele.evaluate(X_train, Y_train)\n",
    "\n",
    "print('====================')\n",
    "\n",
    "# modele.fit(X_train, Y_train, epochs=1000, batch_size=len(X_train), verbose = 1)\n",
    "affiche_poids(modele,0)\n",
    "affiche_poids(modele,1)\n",
    "\n",
    "\n",
    "\n",
    "# print('========= Erreurs ===========')\n",
    "# liste_erreur = []\n",
    "# for i in range(1001):\n",
    "#     loss = modele.train_on_batch(X_train, Y_train)  # renvoie l'erreur avant l'application du gradient\n",
    "#     liste_erreur.append(loss)\n",
    "#     print('loss',loss)\n",
    "#     modele.evaluate(X_train, Y_train)\n",
    "# print(\"Liste des erreurs\", liste_erreur)\n",
    "\n",
    "\n",
    "\n",
    "# # idem mais une époque à la fois\n",
    "# permet d'afficher les gradients\n",
    "# poids_a_zeros(modele,0)  # tous les poids à zéros\n",
    "# poids_a_zeros(modele,0)  # couche 0, tous les poids à zéros\n",
    "# poids_a_zeros(modele,1)  # couche 0, tous les poids à zéros\n",
    "\n",
    "# modele.evaluate(X_train, Y_train)\n",
    "# learning_rate = K.eval(mysgd.learning_rate)  # learning rate\n",
    "\n",
    "# for i in range(1):\n",
    "#     poids_avant = modele.get_weights()\n",
    "#     gradient = get_weight_grad(modele, X_train, Y_train)\n",
    "#     loss = modele.train_on_batch(X_train, Y_train)  # renvoie l'erreur avant l'application du gradient\n",
    "#     poids_apres = modele.get_weights()\n",
    "#     poids_calculer_alamain = [poids_avant[i] - learning_rate*gradient[i] for i in range(len(poids_avant))]\n",
    "#     print(\"\\n==== Epoque numéro\",i)\n",
    "\n",
    "#     print(\"Poids avant\",poids_avant)  \n",
    "#     print(\"Gradient\",gradient)\n",
    "#     print(\"Poids après, par keras\",poids_apres)\n",
    "#     # print(\"Poids calculer à la main\",poids_calculer_alamain)\n",
    "#     print(\"Erreur\",loss)\n",
    "\n",
    "\n",
    "print(\"Gradient à la main par différence de poids\")\n",
    "learning_rate = K.eval(mysgd.learning_rate)  # learning rate\n",
    "gradient=[]\n",
    "for i in range(1):\n",
    "    poids_avant = modele.get_weights()\n",
    "    loss = modele.train_on_batch(X_train, Y_train)  # renvoie l'erreur avant l'application du gradient\n",
    "    poids_apres = modele.get_weights()\n",
    "    gradient = [-1/learning_rate*(poids_apres[i] - poids_avant[i]) for i in range(len(poids_avant))]\n",
    "    print(\"\\n==== Epoque numéro\",i)\n",
    "\n",
    "    print(\"Poids avant\",poids_avant)  \n",
    "    print(\"Poids après, par keras\",poids_apres)\n",
    "    print(\"Gradient\",gradient)\n",
    "\n",
    "\n",
    "\n",
    "poids = modele.get_weights()\n",
    "liste_poids = [ poids[0][0][0], poids[0][1][0], poids[1][0], \n",
    "                poids[0][0][1], poids[0][1][1], poids[1][1],\n",
    "                poids[2][0][0], poids[2][1][0], poids[3][0] ]\n",
    "liste_gradient = [ gradient[0][0][0], gradient[0][1][0], gradient[1][0], \n",
    "                gradient[0][0][1], gradient[0][1][1], gradient[1][1],\n",
    "                gradient[2][0][0], gradient[2][1][0], gradient[3][0] ]\n",
    "\n",
    "print(\"poids\\n\",liste_poids)\n",
    "print(\"gradient\\n\",liste_gradient)\n",
    "\n",
    "\n",
    "print(\"Eval en (0,0)\",evaluation(modele,[0,0]))\n",
    "print(\"Eval en (1,1)\",evaluation(modele,[1,1]))\n",
    "print(\"Eval en (1,0)\",evaluation(modele,[1,0]))\n",
    "print(\"Eval en (0,1)\",evaluation(modele,[0,1]))\n",
    "print(\"Eval en (0.2,0.9)\",evaluation(modele,[0.2,0.9]))\n",
    "# Y_train_found = modele.predict(X_train)\n",
    "# Y_test_found = modele.predict(X_test)\n",
    "# Affichage\n",
    "# plt.scatter(X_train, Y_train, s=100,  color='blue')\n",
    "# plt.scatter(X_train, Y_train_found,  color='red')\n",
    "# plt.scatter(X_test, Y_test, s=100,  color='cyan')\n",
    "# plt.scatter(X_test, Y_test_found,  color='green')\n",
    "\n",
    "# X_liste = np.linspace(0,3,30)\n",
    "# Y_liste = model.predict(X_liste)\n",
    "# plt.plot(X_liste,Y_liste)\n",
    "# plt.show()\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
