{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc78b1f",
   "metadata": {},
   "source": [
    "# KERAS\n",
    "    Keras est une librairie de réseaux de neurones écrite en Python et intégrée à TensorFlow. \n",
    "    Elle a été développée dans le but de permettre une expérimentation rapide afin de passer    \n",
    "    de l’idée aux résultats en un minimum de temps. \n",
    "    \n",
    "    La librairie Keras répond aux besoins suivants :\n",
    "\n",
    "    - Prototypage simple et rapide\n",
    "    - Prise en charge des réseaux convolutifs (CNN) et des réseaux récurrents (RNN)\n",
    "    - Déploiement sur CPU ou sur GPU\n",
    "\n",
    "    Nous présentons dans cette page les trois approches fournies par Keras pour construire des réseaux :\n",
    "\n",
    "    - La classe Sequential : ce container permet de décrire un réseau séquentiel en empilant différentes couches.\n",
    "    - L’API Functional : compromis entre la facilité et flexibilité, c'est l’approche la plus utilisée.\n",
    "    - La classe Model : approche bas-niveau, fournit un contrôle total mais ne donne plus accès à la plupart des    \n",
    "      fonctionnalités de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eaa584",
   "metadata": {},
   "source": [
    "## Les tenseurs\n",
    "    La librairie Keras n’utilise pas en interne de tableaux NumPy mais un objet équivalent appelé tenseur. \n",
    "    Les tenseurs peuvent par exemple être stockés sur GPU alors que les tableaux NumPy sont limités aux CPU. \n",
    "    On retrouve de nombreuses similarités :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9daf562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T.shape --> (3, 2)\n",
      "\n",
      "T.dtype --> <dtype: 'float32'>\n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "T = tf.ones((3,2))\n",
    "print(f'T.shape --> {T.shape}\\n')\n",
    "print(f'T.dtype --> {T.dtype}\\n')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339fc75",
   "metadata": {},
   "source": [
    "### Conversion vers un tenseur\n",
    "\n",
    "    Pour stocker les données d’entrée, nous utilisons la syntaxe suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f7ecb6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(4, 3), dtype=int32)\n",
      "tf.Tensor([[1. 1.]], shape=(1, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "Tensor1 = tf.constant([[1, 2, 3],[1, 2, 3],[1, 2, 3],[1, 2, 3]])   # conversion liste => tenseur\n",
    "print(Tensor1)\n",
    "A  = np.ones((1,2))\n",
    "Tensor2 = tf.constant(A)   \n",
    "print (Tensor2)# conversion numpy array => tenseur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea639ac0",
   "metadata": {},
   "source": [
    "    Pour indiquer le type des données en entrée, on peut utiliser le paramètre dtype=tf.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6a8c3d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "Tensor1 = tf.constant([1, 2, 3],dtype=tf.float32)\n",
    "print(Tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0697e2",
   "metadata": {},
   "source": [
    "    Conversion depuis un tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "67ceab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(Tensor1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdf988",
   "metadata": {},
   "source": [
    "## La classe Sequential\n",
    "\n",
    "    Keras fournit une classe container permettant une écriture simple et aisée pour construire des réseaux de    neurones séquentiels.\n",
    "\n",
    "### model.add ( )\n",
    "\n",
    "    La classe modélisant le réseau séquentiel est instancié en premier :    \n",
    "    \n",
    "    model = keras.Sequential(). \n",
    "     \n",
    "    On lui ajoute deux couches de type FC créées en donnant leurs caractéristiques principales.\n",
    "    Une couche est dite fully-connected (FC) lorsque tous les neurones de la couche précédente sont reliés à tous       les neurones de la couche concernée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c146ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add( keras.layers.Dense(32, input_shape=(16,), activation='relu') )\n",
    "model.add( keras.layers.Dense(20) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83f0a0",
   "metadata": {},
   "source": [
    "    Les différents paramètres pour la fonction d’activation : “relu”, “softmax”, “tanh”, “sigmoid”.    \n",
    "    Le paramètre input_shape est optionnel, s’il est omis, Keras utilisera la taille du tenseur fournit pour la    phase d’apprentissage.    \n",
    "## model.summary()\n",
    "\n",
    "    La fonction summary() permet d’afficher une description des différentes couches :\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9ebf1fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,204\n",
      "Trainable params: 1,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa981a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42e155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5f6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed60db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b6c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(X_train_data, Y_train_data), (X_test_data, Y_test_data) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a2324e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "N = X_train_data.shape  # 60 000 données\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba7ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train_data, (N,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ca4e46c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0894c455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([\n",
    "                [[1,1,1,1], [1,1,1,1],\n",
    "                 [1,1,1,1], [1,1,1,1]],\n",
    "                [[1,1,1,1], [1,1,1,1],\n",
    "                 [1,1,1,1], [1,1,1,1]],\n",
    "                [[1,1,1,1], [1,1,1,1],\n",
    "                 [1,1,1,1], [1,1,1,1]]\n",
    "               ])\n",
    "\n",
    "M = arr.shape\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9bb2e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_t = np.reshape(arr, (arr.shape[0],4,4,1))\n",
    "#print(arr_t.shape)\n",
    "#print(arr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c093770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2b97a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test_data, (X_test_data.shape[0],28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7954982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88f06fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efb832fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train_data, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ce8964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "56beaa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== Couche numéro 0 =====\n",
      "Nombre de neurones : 2\n",
      "Nombre d'entrées par neurones : 2\n",
      "Nombre de poids par neurones : 3 \n",
      "\n",
      "    --- Neurone numéro 0 ---\n",
      "    Coefficients [1. 2.]\n",
      "    Biais -3.0\n",
      "    --- Neurone numéro 1 ---\n",
      "    Coefficients [-3. -2.]\n",
      "    Biais 1.0\n",
      "\n",
      "\n",
      "===== Couche numéro 1 =====\n",
      "Nombre de neurones : 1\n",
      "Nombre d'entrées par neurones : 2\n",
      "Nombre de poids par neurones : 3 \n",
      "\n",
      "    --- Neurone numéro 0 ---\n",
      "    Coefficients [1. 1.]\n",
      "    Biais -1.0\n",
      "X_train : [[0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]]\n",
      "Y_train : [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "(4, 2)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from descente import *\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras_facile import *\n",
    "\n",
    "\n",
    "modele = Sequential()\n",
    "\n",
    "# Réseau : \n",
    "# 2 entrées (x,y), \n",
    "# première couche : 2 neurones\n",
    "# seconde couche : 1 neurone\n",
    "# activation = tangente hyperbolique\n",
    "\n",
    "# Première couche : 2 neurones (entrée de dimension 2)\n",
    "modele.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "\n",
    "# Seconde et dernière couche : 1 neurone\n",
    "modele.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "mysgd = optimizers.SGD(learning_rate=1)\n",
    "modele.compile(loss='mean_squared_error', optimizer=mysgd)\n",
    "\n",
    "# poids_a_zeros(modele,0)  # couche 0, tous les poids à zéros\n",
    "# poids_a_zeros(modele,1)  # couche 0, tous les poids à zéros\n",
    "definir_poids(modele,0,0,[1,2],-3)  # couche, rang, [coeffs], biais\n",
    "definir_poids(modele,0,1,[-3,-2],1)  # couche, rang, [coeffs], biais\n",
    "definir_poids(modele,1,0,[1,1],-1)  # couche, rang, [coeffs], biais\n",
    "\n",
    "# definir_poids(modele,0,0,[1,-1],1)  # couche, rang, [coeffs], biais\n",
    "# definir_poids(modele,0,1,[2,-1],-2)  # couche, rang, [coeffs], biais\n",
    "# definir_poids(modele,1,0,[2,-3],-1)  # couche, rang, [coeffs], biais\n",
    "\n",
    "affiche_poids(modele,0)\n",
    "affiche_poids(modele,1)\n",
    "\n",
    "# carré rouge +1\n",
    "# rond bleus 0\n",
    "carres_rouges = [(0,1), (1,0)]\n",
    "ronds_bleus   = [(0,0), (1,1)] \n",
    "\n",
    "X_train = np.array(carres_rouges+ronds_bleus)\n",
    "# rouge = 1, bleu = 0\n",
    "print(f'X_train : {X_train}')\n",
    "Y_train = np.array( [[1]]*len(carres_rouges) + [[0]]*len(ronds_bleus) )\n",
    "\n",
    "print(f'Y_train : {Y_train}')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1f704206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 154s 1us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 16:06:07.966866: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 62s 68ms/step - loss: 4.7210 - accuracy: 0.0755\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 52s 66ms/step - loss: 4.6801 - accuracy: 0.0618\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 53s 68ms/step - loss: 4.1745 - accuracy: 0.0943\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 52s 67ms/step - loss: 3.7867 - accuracy: 0.1445\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 53s 68ms/step - loss: 3.5458 - accuracy: 0.1786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fbe7d060>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# From mpariente https://stackoverflow.com/questions/51140950/\n",
    "def get_weight_grad(model, inputs, outputs):\n",
    "### Gets gradient of model for given inputs and outputs for all weights\n",
    "    grads = model.optimizer.get_gradients(model.total_loss, model.trainable_weights)\n",
    "    symb_inputs = (model._feed_inputs + model._feed_targets + model._feed_sample_weights)\n",
    "    f = K.function(symb_inputs, grads)\n",
    "    x, y, sample_weight = model._standardize_user_data(inputs, outputs)\n",
    "    output_grad = f(x + y + sample_weight)\n",
    "    return output_grad\n",
    "\n",
    "\n",
    "\n",
    "print('====================')\n",
    "\n",
    "# modele.evaluate(X_train, Y_train)\n",
    "\n",
    "print('====================')\n",
    "\n",
    "# modele.fit(X_train, Y_train, epochs=1000, batch_size=len(X_train), verbose = 1)\n",
    "affiche_poids(modele,0)\n",
    "affiche_poids(modele,1)\n",
    "\n",
    "\n",
    "\n",
    "# print('========= Erreurs ===========')\n",
    "# liste_erreur = []\n",
    "# for i in range(1001):\n",
    "#     loss = modele.train_on_batch(X_train, Y_train)  # renvoie l'erreur avant l'application du gradient\n",
    "#     liste_erreur.append(loss)\n",
    "#     print('loss',loss)\n",
    "#     modele.evaluate(X_train, Y_train)\n",
    "# print(\"Liste des erreurs\", liste_erreur)\n",
    "\n",
    "\n",
    "\n",
    "# # idem mais une époque à la fois\n",
    "# permet d'afficher les gradients\n",
    "# poids_a_zeros(modele,0)  # tous les poids à zéros\n",
    "# poids_a_zeros(modele,0)  # couche 0, tous les poids à zéros\n",
    "# poids_a_zeros(modele,1)  # couche 0, tous les poids à zéros\n",
    "\n",
    "# modele.evaluate(X_train, Y_train)\n",
    "# learning_rate = K.eval(mysgd.learning_rate)  # learning rate\n",
    "\n",
    "# for i in range(1):\n",
    "#     poids_avant = modele.get_weights()\n",
    "#     gradient = get_weight_grad(modele, X_train, Y_train)\n",
    "#     loss = modele.train_on_batch(X_train, Y_train)  # renvoie l'erreur avant l'application du gradient\n",
    "#     poids_apres = modele.get_weights()\n",
    "#     poids_calculer_alamain = [poids_avant[i] - learning_rate*gradient[i] for i in range(len(poids_avant))]\n",
    "#     print(\"\\n==== Epoque numéro\",i)\n",
    "\n",
    "#     print(\"Poids avant\",poids_avant)  \n",
    "#     print(\"Gradient\",gradient)\n",
    "#     print(\"Poids après, par keras\",poids_apres)\n",
    "#     # print(\"Poids calculer à la main\",poids_calculer_alamain)\n",
    "#     print(\"Erreur\",loss)\n",
    "\n",
    "\n",
    "print(\"Gradient à la main par différence de poids\")\n",
    "learning_rate = K.eval(mysgd.learning_rate)  # learning rate\n",
    "gradient=[]\n",
    "for i in range(1):\n",
    "    poids_avant = modele.get_weights()\n",
    "    loss = modele.train_on_batch(X_train, Y_train)  # renvoie l'erreur avant l'application du gradient\n",
    "    poids_apres = modele.get_weights()\n",
    "    gradient = [-1/learning_rate*(poids_apres[i] - poids_avant[i]) for i in range(len(poids_avant))]\n",
    "    print(\"\\n==== Epoque numéro\",i)\n",
    "\n",
    "    print(\"Poids avant\",poids_avant)  \n",
    "    print(\"Poids après, par keras\",poids_apres)\n",
    "    print(\"Gradient\",gradient)\n",
    "\n",
    "\n",
    "\n",
    "poids = modele.get_weights()\n",
    "liste_poids = [ poids[0][0][0], poids[0][1][0], poids[1][0], \n",
    "                poids[0][0][1], poids[0][1][1], poids[1][1],\n",
    "                poids[2][0][0], poids[2][1][0], poids[3][0] ]\n",
    "liste_gradient = [ gradient[0][0][0], gradient[0][1][0], gradient[1][0], \n",
    "                gradient[0][0][1], gradient[0][1][1], gradient[1][1],\n",
    "                gradient[2][0][0], gradient[2][1][0], gradient[3][0] ]\n",
    "\n",
    "print(\"poids\\n\",liste_poids)\n",
    "print(\"gradient\\n\",liste_gradient)\n",
    "\n",
    "\n",
    "print(\"Eval en (0,0)\",evaluation(modele,[0,0]))\n",
    "print(\"Eval en (1,1)\",evaluation(modele,[1,1]))\n",
    "print(\"Eval en (1,0)\",evaluation(modele,[1,0]))\n",
    "print(\"Eval en (0,1)\",evaluation(modele,[0,1]))\n",
    "print(\"Eval en (0.2,0.9)\",evaluation(modele,[0.2,0.9]))\n",
    "# Y_train_found = modele.predict(X_train)\n",
    "# Y_test_found = modele.predict(X_test)\n",
    "# Affichage\n",
    "# plt.scatter(X_train, Y_train, s=100,  color='blue')\n",
    "# plt.scatter(X_train, Y_train_found,  color='red')\n",
    "# plt.scatter(X_test, Y_test, s=100,  color='cyan')\n",
    "# plt.scatter(X_test, Y_test_found,  color='green')\n",
    "\n",
    "# X_liste = np.linspace(0,3,30)\n",
    "# Y_liste = model.predict(X_liste)\n",
    "# plt.plot(X_liste,Y_liste)\n",
    "# plt.show()\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
